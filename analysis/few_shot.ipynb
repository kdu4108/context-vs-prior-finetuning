{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv seaborn circuitsvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "from nnsight import NNsight\n",
    "from nnsight.models.LanguageModel import LanguageModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from transformer_lens import HookedTransformer\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import circuitsvis as cv\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from collections import defaultdict\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from analysis.circuit_utils.visualisation import *\n",
    "from analysis.circuit_utils.model import *\n",
    "from analysis.circuit_utils.validation import *\n",
    "from analysis.circuit_utils.few_shot import *\n",
    "from main import load_model_and_tokenizer\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "DATA_ROOT = \"/dlabscratch1/jminder/repositories/context-vs-prior-finetuning/data/BaseFakepedia\"\n",
    "TRAIN_DATA = os.path.join(DATA_ROOT, \"splits/nodup_relpid/train.csv\")\n",
    "VAL_DATA = os.path.join(DATA_ROOT, \"BaseFakepedia_base-ts640/3/models/Llama-2-7b-chat-hf-peftq_proj_k_proj_v_proj_o_proj-bs4-ga4/results/val.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(TRAIN_DATA)\n",
    "val_data = pd.read_csv(VAL_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_few_shot_prompting(model_names, train_data, val_data, shot_range, repeats=1):\n",
    "    results = defaultdict(list)\n",
    "    for model_name in model_names:\n",
    "        model, tokenizer = load_model_and_tokenizer(model_name, True, False, False, None)\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        tokenizer.padding_side = \"left\"\n",
    "        for shot in tqdm(shot_range):\n",
    "            results[model_name].append([])\n",
    "            for _ in trange(repeats, desc=\"Repeats\", position=1):\n",
    "                shot_indices = train_data[::2].sample(30).index\n",
    "                shot_indices = [(i,i+1) for i in shot_indices]\n",
    "                shot_indices = np.array(shot_indices).flatten()\n",
    "                shot_sample = train_data.loc[shot_indices[:shot]]\n",
    "                val_data[\"text\"] = val_data.apply(lambda x: generate_few_shot_prompts(model_name, shot_sample, x[\"context\"], x[\"query\"],context_weight=x[\"weight_context\"]), axis=1)\n",
    "                if shot < 5:\n",
    "                    bs = 16\n",
    "                elif shot < 15:\n",
    "                    bs = 10\n",
    "                elif shot < 20:\n",
    "                    bs = 10\n",
    "                else:\n",
    "                    bs = 5\n",
    "                try:\n",
    "                    acc = validate(model, tokenizer, val_data, batch_size=bs)\n",
    "                    results[model_name][-1].append(acc)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                shot_sample.to_csv(f\"shot_sample_{shot}_{_}.csv\", index=False)                   \n",
    "                print(\"Shots:\", shot, \"Repeat:\", _, \"- Acc:\", results[model_name][-1])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_indices = train_data[::2].sample(30).index\n",
    "shot = 20\n",
    "shot_indices = [(i,i+1) for i in shot_indices]\n",
    "shot_indices = np.array(shot_indices).flatten()\n",
    "shot_sample = train_data.loc[shot_indices[:shot]]\n",
    "val_data[\"text\"] = val_data.apply(lambda x: generate_few_shot_prompts(\"unsloth/llama-3-8b-Instruct-bnb-4bit\", shot_sample, x[\"context\"], x[\"query\"], context_weight=x[\"weight_context\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_sample.to_csv(\"shot_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"unsloth/llama-3-8b-Instruct-bnb-4bit\", \"unsloth/llama-2-7b-chat-bnb-4bit\", \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\"]\n",
    "model_names = [\"unsloth/llama-3-8b-Instruct-bnb-4bit\"] #, \"unsloth/llama-2-7b-chat-bnb-4bit\", \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\"]\n",
    "results = evaluate_few_shot_prompting(model_names, train_data, val_data, [5, 10, 15, 20, 25, 30], repeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = \"/dlabscratch1/public/llm_weights/llama3_hf/Meta-Llama-3-8B-Instruct\"\n",
    "model, tokenizer = load_model_and_tokenizer(BASE_MODEL, True, False, False, None)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(model, tokenizer, val_data, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "shots = [0, 1, 2, 3, 5, 10, 15, 20, 25, 30]\n",
    "\n",
    "fig = go.Figure()\n",
    "for model_name in model_names:\n",
    "    arr = np.array(results[model_name])\n",
    "    print(accs.shape)\n",
    "    accs = arr.mean(axis=1)\n",
    "    stds = arr.std(axis=1)\n",
    "    print(accs)\n",
    "    fig.add_trace(go.Scatter(x=shots, y=accs, mode=\"lines+markers\", error_y=dict(\n",
    "            type='data', # value of error bar given in data coordinates\n",
    "            array=stds,\n",
    "            visible=True), name=model_name))\n",
    "    # plot max\n",
    "    maxs = np.max(arr, axis=1)\n",
    " \n",
    "    fig.add_trace(go.Scatter(x=shots, y=maxs, mode=\"markers\", marker=dict(size=10), name=\"max\"))\n",
    "    \n",
    "    \n",
    "# set width\n",
    "fig.update_layout(width=1000, height=600)\n",
    "# add legend\n",
    "fig.update_layout(showlegend=True)\n",
    "# add x-axis label\n",
    "fig.update_xaxes(title_text=\"Number of Few-Shot Examples\")\n",
    "# add y-axis label\n",
    "fig.update_yaxes(title_text=\"Validation Accuracy\")\n",
    "# add title\n",
    "fig.update_layout(title_text=\"Few-Shot Prompting Evaluation (10 Repeats)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "shots = [0, 1, 2, 3, 5, 10, 15, 20, 25, 30]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=shots, y=llama3, mode=\"lines+markers\", name=\"Llama-3-8B-Instruct-bnb-4bit\"))\n",
    "fig.add_trace(go.Scatter(x=shots, y=mistral, mode=\"lines+markers\", name=\"Mistral-7B-Instruct-v0.2-bnb-4bit\"))\n",
    "fig.add_trace(go.Scatter(x=shots, y=llama2, mode=\"lines+markers\", name=\"Llama-2-7B-Chat-bnb-4bit\"))\n",
    "# set width\n",
    "fig.update_layout(width=1000, height=600)\n",
    "# add legend\n",
    "fig.update_layout(showlegend=True)\n",
    "# add x-axis label\n",
    "fig.update_xaxes(title_text=\"Number of Few-Shot Examples\")\n",
    "# add y-axis label\n",
    "fig.update_yaxes(title_text=\"Validation Accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
